# ğŸ­ Emotion AI - Voice Emotion Detection System

A full-stack AI application that detects emotions from voice recordings using deep learning.

## ğŸš€ Quick Links

- **[Deployment Guide](DEPLOYMENT.md)** - Complete step-by-step deployment instructions
- **[Quick Start](QUICK_START.md)** - Fast track deployment (30 minutes)

---

## ğŸ—ï¸ Architecture

- **Frontend**: React.js (deployed on Vercel)
- **Backend**: Node.js + Express (deployed on Render)
- **ML Service**: Python + Flask + TensorFlow (deployed on Render)
- **Database**: MongoDB Atlas

---

## ğŸ› ï¸ Local Development Setup

### Prerequisites
- Node.js (v14+)
- Python (v3.8+)
- MongoDB (local or Atlas)

### Installation

1. **Clone the repository**
   ```bash
   git clone <your-repo-url>
   cd emotion-ai
   ```

2. **Setup Backend**
   ```bash
   cd backend
   npm install
   ```

3. **Setup Frontend**
   ```bash
   cd frontend
   npm install
   ```

4. **Setup ML Service**
   ```bash
   cd backend/ml_service
   pip install numpy librosa tensorflow flask flask-cors werkzeug
   ```

### Running Locally

1. **Start MongoDB** (if using local)
   ```bash
   mongod
   ```

2. **Start Backend** (Terminal 1)
   ```bash
   cd backend
   node server.js
   ```

3. **Start ML Service** (Terminal 2)
   ```bash
   cd backend/ml_service
   python app.py
   ```

4. **Start Frontend** (Terminal 3)
   ```bash
   cd frontend
   npm start
   ```

5. **Access the app**: http://localhost:3000

---

## ğŸ“¦ Dependencies

### Backend (Node.js)
```bash
npm install express mongoose cors multer form-data node-fetch fs path bcrypt
```

**Packages:**
- express - Web framework for Node.js
- mongoose - ODM (Object Data Modeling) library for MongoDB
- cors - Middleware to enable CORS (Cross-Origin Resource Sharing)
- multer - Middleware for handling file uploads
- form-data - To create and send form data (especially for multipart/form-data)
- node-fetch - To make HTTP requests
- bcrypt - Password hashing
- fs (File System) - Built-in, no need to install
- path - Built-in, no need to install

### ML Service (Python)
```bash
pip install numpy librosa tensorflow flask flask-cors werkzeug
```

**Packages:**
- numpy - For numerical operations
- librosa - For audio processing
- tensorflow - For machine learning and deep learning tasks
- flask - To create a web server
- flask-cors - To handle Cross-Origin Resource Sharing (CORS)
- werkzeug - To handle secure file uploads

### Frontend (React)
```bash
npm install react react-dom react-router-dom
```

---

## ğŸŒ Deployment

### Quick Deployment (30 minutes)
See **[QUICK_START.md](QUICK_START.md)** for fast track deployment.

### Detailed Deployment
See **[DEPLOYMENT.md](DEPLOYMENT.md)** for complete instructions.

### Deployment Platforms
- **Frontend**: Vercel (Free tier available)
- **Backend**: Render (Free tier available)
- **ML Service**: Render (Free tier available)
- **Database**: MongoDB Atlas (Free tier available)

---

## ğŸ” Environment Variables

### Backend (.env)
```env
MONGODB_URI=mongodb://127.0.0.1:27017/emotionAI
PORT=8000
FRONTEND_URL=http://localhost:3000
ML_SERVICE_URL=http://localhost:5000
```

### Frontend (.env)
```env
REACT_APP_API_URL=http://localhost:8000
```

---

## ğŸ“ Project Structure

```
emotion-ai/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ config/          # Database configuration
â”‚   â”œâ”€â”€ controllers/     # Request handlers
â”‚   â”œâ”€â”€ middleware/      # Custom middleware
â”‚   â”œâ”€â”€ models/          # MongoDB schemas
â”‚   â”œâ”€â”€ routes/          # API routes
â”‚   â”œâ”€â”€ ml_service/      # Python ML service
â”‚   â”‚   â”œâ”€â”€ app.py
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ sound_to_emotion_model3.keras
â”‚   â”œâ”€â”€ server.js        # Main server file
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ config.js    # API configuration
â”‚   â”‚   â””â”€â”€ App.js
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ DEPLOYMENT.md        # Detailed deployment guide
â”œâ”€â”€ QUICK_START.md       # Quick deployment guide
â””â”€â”€ README.md
```

---

## ğŸ¯ Features

- ğŸ¤ Voice emotion detection from audio files
- ğŸ‘¤ User authentication and authorization
- ğŸ“Š Detailed emotion analysis reports
- ğŸ“ˆ Emotion probability distribution
- ğŸ’¾ Historical data tracking
- ğŸ¨ Modern, responsive UI
- ğŸ”’ Secure password hashing
- â˜ï¸ Cloud-ready architecture

---

## ğŸ§ª Testing

After deployment, test your application:

1. Visit your Vercel URL
2. Create a new account
3. Upload an audio file (.wav format recommended)
4. View emotion detection results
5. Check your reports page

---

## ğŸ› Troubleshooting

### Common Issues

**Frontend can't connect to backend:**
- Verify `REACT_APP_API_URL` is set correctly
- Check CORS configuration in backend
- Ensure backend is running

**ML service errors:**
- Check if model file exists
- Verify Python dependencies are installed
- Check Render logs for errors

**Database connection issues:**
- Verify MongoDB connection string
- Check IP whitelist in MongoDB Atlas
- Ensure database user has correct permissions

---

## ğŸ“ License

MIT

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

---

## ğŸ“§ Support

For issues and questions, please open an issue on GitHub.

---

## ğŸ‰ Acknowledgments

- TensorFlow for ML framework
- Librosa for audio processing
- React for frontend framework
- Express for backend framework